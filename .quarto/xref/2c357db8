{"entries":[{"caption":"14  Security & Privacy","key":"sec-security_privacy","order":{"number":1,"section":[14,0,0,0,0,0,0]}},{"caption":"Power analysis of an encryption device with a (partially) wrong password. Source: Colin O’Flynn.","key":"fig-encryption2","order":{"number":5,"section":[14,5,4,0,0,0,0]}},{"caption":"Data poisoning. Source: @shan2023prompt.","key":"fig-poisoning","order":{"number":2,"section":[14,4,2,2,0,0,0]}},{"caption":"Jeep Cherokee Hack","key":"vid-jeephack","order":{"number":1,"section":[14,3,2,0,0,0,0]}},{"caption":"System-on-chip secure enclave. Source: Apple.","key":"fig-enclave","order":{"number":7,"section":[14,6,1,3,0,0,0]}},{"caption":"Differential Privacy - TensorFlow Privacy","key":"exr-dptf","order":{"number":1,"section":[14,8,1,3,0,0,0]}},{"caption":"Power Attack","key":"vid-powerattack","order":{"number":3,"section":[14,5,4,0,0,0,0]}},{"caption":"Stuxnet explained. Source: IEEE Spectrum","key":"fig-stuxnet","order":{"number":1,"section":[14,3,1,0,0,0,0]}},{"caption":"Reverse psychology to bypass safety restrictions. Source: @Gupta2023ChatGPT.","key":"fig-role-play2","order":{"number":11,"section":[14,7,6,1,1,0,0]}},{"caption":"Privacy-accuracy tradeoff. Source: @abadi2016deep.","key":"fig-tradeoffs","order":{"number":12,"section":[14,8,1,1,0,0,0]}},{"caption":"Comparing techniques for privacy-preserving machine learning.","key":"tbl-privacy-techniques","order":{"number":2,"section":[14,8,7,0,0,0,0]}},{"caption":"Llama unlearning Harry Potter. Source: @eldan2023whos.","key":"fig-hp-prompts","order":{"number":15,"section":[14,8,3,2,0,0,0]}},{"caption":"PUF basics. Source: @Gao2020Physical.","key":"fig-pfu","order":{"number":9,"section":[14,6,4,4,0,0,0]}},{"caption":"14.10 Resources","key":"sec-security-and-privacy-resource","order":{"number":1,"section":[14,10,0,0,0,0,0]}},{"caption":"Fault-injection demonstrated with assembly code. Source: @breier2018deeplaser.","key":"fig-injection","order":{"number":3,"section":[14,5,3,0,0,0,0]}},{"caption":"Secure Boot flow. Source: @Rashmi2018Secure.","key":"fig-secure-boot","order":{"number":8,"section":[14,6,2,3,0,0,0]}},{"caption":"Threat types on hardware security.","key":"tbl-threat_types","order":{"number":1,"section":[14,5,0,0,0,0,0]}},{"caption":"Grandma role play to bypass safety restrictions. Source: @Gupta2023ChatGPT.","key":"fig-role-play","order":{"number":10,"section":[14,7,6,1,1,0,0]}},{"caption":"Flowchart of GANs. Source: @rosa2021.","key":"fig-gans","order":{"number":16,"section":[14,8,6,1,0,0,0]}},{"caption":"Mirai Botnet","key":"vid-mirai","order":{"number":2,"section":[14,3,3,0,0,0,0]}},{"caption":"Homomorphic Encryption","key":"exr-he","order":{"number":2,"section":[14,8,4,4,0,0,0]}},{"caption":"Power analysis of an encryption device with a wrong password. Source: Colin O’Flynn.","key":"fig-encryption3","order":{"number":6,"section":[14,5,4,0,0,0,0]}},{"caption":"Applications of Machine Unlearning. Source: BBVA OpenMind","key":"fig-machine-unlearning","order":{"number":14,"section":[14,8,3,1,0,0,0]}},{"caption":"Federated Learning lifecycle. Source: @jin2020towards.","key":"fig-fl-lifecycle","order":{"number":13,"section":[14,8,2,1,0,0,0]}},{"caption":"Power analysis of an encryption device with a correct password. Source: Colin O’Flynn.","key":"fig-encryption","order":{"number":4,"section":[14,5,4,0,0,0,0]}}],"headings":["introduction","terminology","historical-precedents","stuxnet","jeep-cherokee-hack","mirai-botnet","implications","security-threats-to-ml-models","model-theft","stealing-exact-model-properties","stealing-approximate-model-behavior","case-study","data-poisoning","case-study-1","case-study-2","adversarial-attacks","case-study-3","security-threats-to-ml-hardware","hardware-bugs","physical-attacks","fault-injection-attacks","side-channel-attacks","leaky-interfaces","counterfeit-hardware","supply-chain-risks","case-study-4","embedded-ml-hardware-security","trusted-execution-environments","about-tee","benefits","mechanics","tradeoffs","secure-boot","about","benefits-1","mechanics-1","case-study-apples-face-id","challenges","hardware-security-modules","about-hsm","benefits-2","tradeoffs-1","physical-unclonable-functions-pufs","about-1","benefits-3","utility","mechanics-2","challenges-1","privacy-concerns-in-data-handling","sensitive-data-types","applicable-regulations","de-identification","safe-harbor-methods","expert-determination-methods","data-minimization","case-study---performance-based-data-minimization","consent-and-transparency","privacy-concerns-in-machine-learning","generative-ai","case-study-5","data-erasure","privacy-preserving-ml-techniques","differential-privacy","core-idea","tradeoffs-2","case-study-6","federated-learning","core-idea-1","tradeoffs-3","case-studies","google-gboard","healthcare-research","financial-services","machine-unlearning","core-idea-2","case-study-7","other-uses","removing-adversarial-data","homomorphic-encryption","core-idea-3","benefits-4","mechanics-3","tradeoffs-4","secure-multiparty-communication","core-idea-4","tradeoffs-5","synthetic-data-generation","core-idea-5","benefits-5","tradeoffs-6","summary","conclusion","sec-security-and-privacy-resource","sec-security_privacy"],"options":{"appendix-delim":":","appendix-title":"Appendix","chapter-id":"sec-security_privacy","chapters":true,"custom":["labqfloatlabLab","exrfloatexrExercise","vidfloatvidVideo"]}}