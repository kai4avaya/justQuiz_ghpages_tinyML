{"entries":[{"caption":"8  Efficient AI","key":"sec-efficient_ai","order":{"number":1,"section":[8,0,0,0,0,0,0]}},{"caption":"8.6 Efficient Numerics","key":"sec-efficient-numerics","order":{"number":2,"section":[8,6,0,0,0,0,0]}},{"caption":"8.6.2 Efficiency Benefits","key":"sec-efficiency-benefits","order":{"number":4,"section":[8,6,2,0,0,0,0]}},{"caption":"8.6.1 Numerical Formats","key":"sec-numerical-formats","order":{"number":3,"section":[8,6,1,0,0,0,0]}},{"caption":"Different forms of quantization.","key":"fig-quantization","order":{"number":3,"section":[8,4,0,0,0,0,0]}},{"caption":"Neural Network Pruning.","key":"fig-pruning","order":{"number":2,"section":[8,4,0,0,0,0,0]}},{"caption":"Accelerator vs CPU performance comparison across different hardware configurations. Desktop CPU: 64-bit Intel(R) Xeon(R) E5-1650 v4 @ 3.60GHz. Embedded CPU: Quad-core Cortex-A53 @ 1.5GHz, †Dev Board: Quad-core Cortex-A53 @ 1.5GHz + Edge TPU. Source: TensorFlow Blog.","key":"fig-edge-tpu-perf","order":{"number":5,"section":[8,5,0,0,0,0,0]}},{"caption":"8.9 Resources","key":"sec-efficient-ai-resource","order":{"number":5,"section":[8,9,0,0,0,0,0]}},{"caption":"Comparing precision levels in deep learning.","key":"tbl-precision","order":{"number":1,"section":[8,6,1,0,0,0,0]}},{"caption":"Cloud, Mobile and TinyML. Source: @schizas2022tinyml.","key":"fig-platforms","order":{"number":1,"section":[8,2,0,0,0,0,0]}},{"caption":"Three floating-point formats.","key":"fig-float-point-formats","order":{"number":6,"section":[8,6,1,0,0,0,0]}},{"caption":"8.4 Efficient Model Compression","key":"sec-efficient-model-compression","order":{"number":1,"section":[8,4,0,0,0,0,0]}},{"caption":"Floating Point Numbers","key":"vid-floating-point-numbers","order":{"number":1,"section":[8,6,1,0,0,0,0]}},{"caption":"Different types of stoves. Source: Dollar Street stove images.","key":"fig-stoves","order":{"number":7,"section":[8,7,2,0,0,0,0]}},{"caption":"The tutor-student framework for knowledge distillation. Source: Medium","key":"fig-knowledge-dist","order":{"number":4,"section":[8,4,0,0,0,0,0]}}],"headings":["overview","the-need-for-efficient-ai","efficient-model-architectures","sec-efficient-model-compression","efficient-inference-hardware","sec-efficient-numerics","sec-numerical-formats","sec-efficiency-benefits","evaluating-models","efficiency-metrics","efficiency-comparisons","conclusion","sec-efficient-ai-resource","sec-efficient_ai"],"options":{"appendix-delim":":","appendix-title":"Appendix","chapter-id":"sec-efficient_ai","chapters":true,"custom":["labqfloatlabLab","exrfloatexrExercise","vidfloatvidVideo"]}}